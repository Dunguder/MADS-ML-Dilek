{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow for a data science project will follow these lines:\n",
    "\n",
    "1. Get and explore the data\n",
    "2. Build a model \n",
    "3. Train the model\n",
    "4. Save and predict\n",
    "\n",
    "## 1. Get and Explore the Data\n",
    "The first step can take quite some time; data quality is often something that needs to be checked, and correlations between data should often be explored and visualized.\n",
    "\n",
    "This step can be a full project on its own: you clean the data, make sure you can access it properly, and create visualizations and hypothesis to gain insight into the data that can be shown in a dashboard.\n",
    "\n",
    "The insight in the data is an essential ingredient for deciding on a model.\n",
    "\n",
    "## 2. Build a model\n",
    "Based on domain knowledge and a first exploration of the data, a model can be selected.\n",
    "\n",
    "Sometimes, the relation between features and outcome is very obvious. You might have features that\n",
    "correlate very high with the outcome variable, and a domain expert confirms that the correlations make sense.\n",
    "\n",
    "If this is the case, you can often build a simple model. If you expect to have non-linear and complex interactions between the features,\n",
    "you could use a model that works with non-linear data like a SVM plus kernel, or a random forest.\n",
    "\n",
    "If you have enough data (as a rule of thumb, a lower threshold of 1000 observations) you can consider a neural network architecture.\n",
    "If the expected complexity of the data is low, you can use a relative small network.\n",
    "If you have lots and lots of data with a high complexity, you should consider to increase the complexity of your model too.\n",
    "\n",
    "How you can build a model, and what suitable models are for different datatypes and situations, will be the subject of the whole course.\n",
    "\n",
    "## 3. Train the model\n",
    "Once you created a model, it hasnt learned anything yet. The model must be trained to learn the right connections, a bit like a baby that has to learn about what works and what doesn't.\n",
    "\n",
    "In this notebook, I will introduce you to PyTorch. Another high level library is Tensorflow, which is used a lot too.\n",
    "While the interface is comparable, the Tensorflow syntax is a bit more high-level. While this can be an advantage, \n",
    "it also has a downside: at the moment you ever need to dive a bit deeper into the architecture itself, it is much harder to\n",
    "add something new with TensorFlow, compared to PyTorch.\n",
    "\n",
    "## 4. Save and predict\n",
    "Finally, you will want to use the trained model to predict new observations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "We will use the fashion MNIST dataset. You will find this dataset a lot in machine learning tutorials. It are small (28x28) images of clothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.12'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import mads_datasets\n",
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "\n",
    "mads_datasets.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-16 14:32:44.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\dilek\\.cache\\mads_datasets\\fashionmnist\u001b[0m\n",
      "\u001b[32m2024-11-16 14:32:44.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at C:\\Users\\dilek\\.cache\\mads_datasets\\fashionmnist\\fashionmnist.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "datasets = fashionfactory.create_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a `Dataset`. They implement at minimum an `.__getitem__` and `.__len__` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTDataset (len 60000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data, we can use the `__getitem__` method by calling an index, just like you would do with a list or array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, torch.Tensor, torch.Tensor, tensor(1.), tensor(0.), torch.float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = datasets[\"train\"][0]\n",
    "type(x), type(x[0]), type(x[1]), x[0].max(), x[0].min(), x[0].dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to this (but no one does that, obviously. We implement the dunder method to make life easier, not more complex...):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = datasets[\"train\"].__getitem__(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a tuple. We can check the length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the 0th item, which is the image (tensor). The other item is the label (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = x[0]\n",
    "img.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the image has a channel-first convention: it is a 28x28 pixel image, and it has 1 channel (grey). Look into the official documentation if you want to know more about datasets and how to build your own: [docs](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "Ok, we want to batch this into a dataloader. From the documentation:\n",
    "\n",
    "> The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is the length of the dataloader different from the dataset? We had 60000 items before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can either use pytorches DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "trainloader = DataLoader(datasets[\"train\"], batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(datasets[\"valid\"], batch_size=64, shuffle=True)\n",
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.34 ms ± 810 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit X, y = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "preprocessor = BasePreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-16 14:34:14.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\dilek\\.cache\\mads_datasets\\fashionmnist\u001b[0m\n",
      "\u001b[32m2024-11-16 14:34:14.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at C:\\Users\\dilek\\.cache\\mads_datasets\\fashionmnist\\fashionmnist.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# or the BaseDatastreamer from the datasetfactory. Check out which one is faster\n",
    "\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=64, preprocessor=preprocessor )\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(trainstreamer))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 ms ± 210 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit X, y = next(iter(trainstreamer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 156)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(trainstreamer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what do we see here? Our datashape has four dimensions:\n",
    "\n",
    "- 64: this is the batch size. Every batch has 64 observations; in this case 64 images\n",
    "- 1: this is the channel. Colorimages typically have 3 channels. Our images have just one color, and thus 1 channel. So images can have more channels (e.g. infrared etc)\n",
    "- (28,28) : this is the actual image, with dimensions 28x28\n",
    "\n",
    "Lets visualize the first example, the first image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = X[1]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c6cb3b0950>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-16 14:35:15.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mUsing cpu device\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 512]         401,920\n",
      "              ReLU-3                  [-1, 512]               0\n",
      "            Linear-4                  [-1, 256]         131,328\n",
      "              ReLU-5                  [-1, 256]               0\n",
      "            Linear-6                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 2.04\n",
      "Estimated Total Size (MB): 2.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from loguru import logger\n",
    "\n",
    "logger.info(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(\"cpu\")\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you recognize the setup from the `linearmodel` notebook. \n",
    "\n",
    "- We will `Flatten` the image. That means we will transform our (64, 1, 28, 28) data into (64, 784) shaped data. What we do here, is flattening the image into a one dimensional vector.\n",
    "- We have a stack of hidden layers. These are essentially dotproducts. Our vector of 784 (28*28) elements is transformed into 512 elements, and then into 10 elements because we have 10 classes.\n",
    "- in between the linear transformations you can see the activation functions,here a `ReLu` \n",
    "- The `forward` method is what is called during training. This gives you control over the flow of information: it is easy to create some parallel flow of data if you want to do something like that."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an optimizer. We will dive into this in later lessons.\n",
    "\n",
    "For now, it is enough to know this:\n",
    "\n",
    "Your model makes a prediction. But how does the model know if it is right, or wrong?\n",
    "And, more specific: how does the model know which weights it needs to modify in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(trainstreamer))\n",
    "model.to(device)\n",
    "next(model.parameters()).is_cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model(X.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2773, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(yhat, y.to(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/dilek/desktop/Advanced_AI_Applications_WS24-25_MADS_HSRW/notebooks/1_pytorch_intro/logs')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir=Path(\"logs\").absolute()\n",
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer import metrics\n",
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-16 14:36:28.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir C:\\Users\\dilek\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\notebooks\\1_pytorch_intro\\logs\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "epochs: 3\n",
       "metrics: [Accuracy]\n",
       "logdir: C:\\Users\\dilek\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\notebooks\\1_pytorch_intro\\logs\n",
       "train_steps: 937\n",
       "valid_steps: 156\n",
       "reporttypes: [<ReportTypes.TENSORBOARD: 2>]\n",
       "optimizer_kwargs: {'lr': 0.001, 'weight_decay': 1e-05}\n",
       "scheduler_kwargs: {'factor': 0.1, 'patience': 10}\n",
       "earlystop_kwargs: {'save': False, 'verbose': True, 'patience': 10}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mltrainer import TrainerSettings, ReportTypes, Trainer\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=3,\n",
    "    metrics=[accuracy],\n",
    "    logdir=log_dir,\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD],\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-16 14:36:49.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to C:\\Users\\dilek\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\notebooks\\1_pytorch_intro\\logs\\20241116-143649\u001b[0m\n",
      "\u001b[32m2024-11-16 14:36:50.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[38;2;30;71;6m                                                                                            \u001b[0m| 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                          \u001b[0m| 0/937 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "  1%|\u001b[38;2;30;71;6m▊                                                                                 \u001b[0m| 9/937 [00:00<00:10, 85.41it/s]\u001b[0m\u001b[A\n",
      "  2%|\u001b[38;2;30;71;6m█▉                                                                              \u001b[0m| 22/937 [00:00<00:08, 110.82it/s]\u001b[0m\u001b[A\n",
      "  4%|\u001b[38;2;30;71;6m███▏                                                                            \u001b[0m| 38/937 [00:00<00:06, 131.29it/s]\u001b[0m\u001b[A\n",
      "  6%|\u001b[38;2;30;71;6m████▋                                                                           \u001b[0m| 55/937 [00:00<00:06, 144.84it/s]\u001b[0m\u001b[A\n",
      "  7%|\u001b[38;2;30;71;6m█████▉                                                                          \u001b[0m| 70/937 [00:00<00:05, 144.68it/s]\u001b[0m\u001b[A\n",
      "  9%|\u001b[38;2;30;71;6m███████▎                                                                        \u001b[0m| 85/937 [00:00<00:06, 141.60it/s]\u001b[0m\u001b[A\n",
      " 11%|\u001b[38;2;30;71;6m████████▌                                                                      \u001b[0m| 101/937 [00:00<00:05, 146.86it/s]\u001b[0m\u001b[A\n",
      " 12%|\u001b[38;2;30;71;6m█████████▊                                                                     \u001b[0m| 117/937 [00:00<00:05, 149.03it/s]\u001b[0m\u001b[A\n",
      " 14%|\u001b[38;2;30;71;6m███████████▏                                                                   \u001b[0m| 133/937 [00:00<00:05, 151.25it/s]\u001b[0m\u001b[A\n",
      " 16%|\u001b[38;2;30;71;6m████████████▌                                                                  \u001b[0m| 149/937 [00:01<00:05, 153.67it/s]\u001b[0m\u001b[A\n",
      " 18%|\u001b[38;2;30;71;6m█████████████▉                                                                 \u001b[0m| 165/937 [00:01<00:05, 154.23it/s]\u001b[0m\u001b[A\n",
      " 19%|\u001b[38;2;30;71;6m███████████████▎                                                               \u001b[0m| 181/937 [00:01<00:04, 155.05it/s]\u001b[0m\u001b[A\n",
      " 21%|\u001b[38;2;30;71;6m████████████████▌                                                              \u001b[0m| 197/937 [00:01<00:04, 151.67it/s]\u001b[0m\u001b[A\n",
      " 23%|\u001b[38;2;30;71;6m█████████████████▉                                                             \u001b[0m| 213/937 [00:01<00:04, 146.22it/s]\u001b[0m\u001b[A\n",
      " 24%|\u001b[38;2;30;71;6m███████████████████▎                                                           \u001b[0m| 229/937 [00:01<00:04, 148.41it/s]\u001b[0m\u001b[A\n",
      " 26%|\u001b[38;2;30;71;6m████████████████████▋                                                          \u001b[0m| 245/937 [00:01<00:04, 151.48it/s]\u001b[0m\u001b[A\n",
      " 28%|\u001b[38;2;30;71;6m██████████████████████                                                         \u001b[0m| 261/937 [00:01<00:04, 149.69it/s]\u001b[0m\u001b[A\n",
      " 30%|\u001b[38;2;30;71;6m███████████████████████▎                                                       \u001b[0m| 277/937 [00:01<00:04, 148.48it/s]\u001b[0m\u001b[A\n",
      " 31%|\u001b[38;2;30;71;6m████████████████████████▊                                                      \u001b[0m| 294/937 [00:01<00:04, 152.58it/s]\u001b[0m\u001b[A\n",
      " 33%|\u001b[38;2;30;71;6m██████████████████████████▏                                                    \u001b[0m| 310/937 [00:02<00:04, 136.32it/s]\u001b[0m\u001b[A\n",
      " 35%|\u001b[38;2;30;71;6m███████████████████████████▍                                                   \u001b[0m| 326/937 [00:02<00:04, 141.23it/s]\u001b[0m\u001b[A\n",
      " 36%|\u001b[38;2;30;71;6m████████████████████████████▊                                                  \u001b[0m| 341/937 [00:02<00:04, 141.63it/s]\u001b[0m\u001b[A\n",
      " 38%|\u001b[38;2;30;71;6m██████████████████████████████                                                 \u001b[0m| 356/937 [00:02<00:04, 142.27it/s]\u001b[0m\u001b[A\n",
      " 40%|\u001b[38;2;30;71;6m███████████████████████████████▎                                               \u001b[0m| 371/937 [00:02<00:03, 143.54it/s]\u001b[0m\u001b[A\n",
      " 41%|\u001b[38;2;30;71;6m████████████████████████████████▌                                              \u001b[0m| 386/937 [00:02<00:03, 142.25it/s]\u001b[0m\u001b[A\n",
      " 43%|\u001b[38;2;30;71;6m█████████████████████████████████▊                                             \u001b[0m| 401/937 [00:02<00:03, 138.55it/s]\u001b[0m\u001b[A\n",
      " 44%|\u001b[38;2;30;71;6m███████████████████████████████████                                            \u001b[0m| 416/937 [00:02<00:03, 141.14it/s]\u001b[0m\u001b[A\n",
      " 46%|\u001b[38;2;30;71;6m████████████████████████████████████▎                                          \u001b[0m| 431/937 [00:02<00:03, 142.81it/s]\u001b[0m\u001b[A\n",
      " 48%|\u001b[38;2;30;71;6m█████████████████████████████████████▌                                         \u001b[0m| 446/937 [00:03<00:03, 140.02it/s]\u001b[0m\u001b[A\n",
      " 49%|\u001b[38;2;30;71;6m██████████████████████████████████████▊                                        \u001b[0m| 461/937 [00:03<00:03, 140.35it/s]\u001b[0m\u001b[A\n",
      " 51%|\u001b[38;2;30;71;6m████████████████████████████████████████▏                                      \u001b[0m| 476/937 [00:03<00:03, 138.24it/s]\u001b[0m\u001b[A\n",
      " 52%|\u001b[38;2;30;71;6m█████████████████████████████████████████▎                                     \u001b[0m| 490/937 [00:03<00:03, 138.59it/s]\u001b[0m\u001b[A\n",
      " 54%|\u001b[38;2;30;71;6m██████████████████████████████████████████▍                                    \u001b[0m| 504/937 [00:03<00:03, 135.36it/s]\u001b[0m\u001b[A\n",
      " 55%|\u001b[38;2;30;71;6m███████████████████████████████████████████▋                                   \u001b[0m| 518/937 [00:03<00:03, 132.84it/s]\u001b[0m\u001b[A\n",
      " 57%|\u001b[38;2;30;71;6m████████████████████████████████████████████▊                                  \u001b[0m| 532/937 [00:03<00:03, 131.25it/s]\u001b[0m\u001b[A\n",
      " 58%|\u001b[38;2;30;71;6m██████████████████████████████████████████████                                 \u001b[0m| 546/937 [00:03<00:02, 132.18it/s]\u001b[0m\u001b[A\n",
      " 60%|\u001b[38;2;30;71;6m███████████████████████████████████████████████▏                               \u001b[0m| 560/937 [00:03<00:02, 133.45it/s]\u001b[0m\u001b[A\n",
      " 61%|\u001b[38;2;30;71;6m████████████████████████████████████████████████▍                              \u001b[0m| 575/937 [00:04<00:02, 134.74it/s]\u001b[0m\u001b[A\n",
      " 63%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████▋                             \u001b[0m| 589/937 [00:04<00:02, 135.54it/s]\u001b[0m\u001b[A\n",
      " 64%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████▊                            \u001b[0m| 603/937 [00:04<00:02, 134.81it/s]\u001b[0m\u001b[A\n",
      " 66%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████                           \u001b[0m| 617/937 [00:04<00:02, 135.76it/s]\u001b[0m\u001b[A\n",
      " 67%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████▎                         \u001b[0m| 632/937 [00:04<00:02, 137.41it/s]\u001b[0m\u001b[A\n",
      " 69%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████▍                        \u001b[0m| 646/937 [00:04<00:02, 134.10it/s]\u001b[0m\u001b[A\n",
      " 70%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████▋                       \u001b[0m| 660/937 [00:04<00:02, 132.39it/s]\u001b[0m\u001b[A\n",
      " 72%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████▊                      \u001b[0m| 674/937 [00:04<00:01, 132.20it/s]\u001b[0m\u001b[A\n",
      " 74%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████                     \u001b[0m| 689/937 [00:04<00:01, 136.57it/s]\u001b[0m\u001b[A\n",
      " 75%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████▍                   \u001b[0m| 705/937 [00:05<00:01, 141.71it/s]\u001b[0m\u001b[A\n",
      " 77%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████▋                  \u001b[0m| 720/937 [00:05<00:01, 144.01it/s]\u001b[0m\u001b[A\n",
      " 78%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████▉                 \u001b[0m| 735/937 [00:05<00:01, 141.69it/s]\u001b[0m\u001b[A\n",
      " 80%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████▏               \u001b[0m| 750/937 [00:05<00:01, 141.03it/s]\u001b[0m\u001b[A\n",
      " 82%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████▍              \u001b[0m| 765/937 [00:05<00:01, 138.90it/s]\u001b[0m\u001b[A\n",
      " 83%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████▋             \u001b[0m| 779/937 [00:05<00:01, 138.26it/s]\u001b[0m\u001b[A\n",
      " 85%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████▊            \u001b[0m| 793/937 [00:05<00:01, 136.72it/s]\u001b[0m\u001b[A\n",
      " 86%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████           \u001b[0m| 807/937 [00:05<00:00, 137.50it/s]\u001b[0m\u001b[A\n",
      " 88%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████████▎         \u001b[0m| 822/937 [00:05<00:00, 138.82it/s]\u001b[0m\u001b[A\n",
      " 89%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████▍        \u001b[0m| 836/937 [00:05<00:00, 136.06it/s]\u001b[0m\u001b[A\n",
      " 91%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████▋       \u001b[0m| 850/937 [00:06<00:00, 134.99it/s]\u001b[0m\u001b[A\n",
      " 92%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████████████      \u001b[0m| 866/937 [00:06<00:00, 140.40it/s]\u001b[0m\u001b[A\n",
      " 94%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████████▎    \u001b[0m| 881/937 [00:06<00:00, 139.99it/s]\u001b[0m\u001b[A\n",
      " 96%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████████▋   \u001b[0m| 897/937 [00:06<00:00, 144.69it/s]\u001b[0m\u001b[A\n",
      " 97%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████████████▉  \u001b[0m| 912/937 [00:06<00:00, 143.41it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████████████\u001b[0m| 937/937 [00:06<00:00, 139.73it/s]\u001b[0m\u001b[A\n",
      "\u001b[32m2024-11-16 14:37:04.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mEpoch 0 train 0.5001 test 0.4110 metric ['0.8482']\u001b[0m\n",
      " 33%|\u001b[38;2;30;71;6m████████████████████████████                                                        \u001b[0m| 1/3 [00:07<00:14,  7.11s/it]\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                          \u001b[0m| 0/937 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "  1%|\u001b[38;2;30;71;6m█                                                                               \u001b[0m| 13/937 [00:00<00:07, 125.42it/s]\u001b[0m\u001b[A\n",
      "  3%|\u001b[38;2;30;71;6m██▍                                                                             \u001b[0m| 28/937 [00:00<00:06, 136.52it/s]\u001b[0m\u001b[A\n",
      "  4%|\u001b[38;2;30;71;6m███▌                                                                            \u001b[0m| 42/937 [00:00<00:07, 119.85it/s]\u001b[0m\u001b[A\n",
      "  6%|\u001b[38;2;30;71;6m████▋                                                                           \u001b[0m| 55/937 [00:00<00:08, 103.44it/s]\u001b[0m\u001b[A\n",
      "  7%|\u001b[38;2;30;71;6m█████▋                                                                           \u001b[0m| 66/937 [00:00<00:08, 97.45it/s]\u001b[0m\u001b[A\n",
      "  8%|\u001b[38;2;30;71;6m██████▌                                                                          \u001b[0m| 76/937 [00:00<00:08, 97.41it/s]\u001b[0m\u001b[A\n",
      "  9%|\u001b[38;2;30;71;6m███████▍                                                                         \u001b[0m| 86/937 [00:00<00:08, 97.53it/s]\u001b[0m\u001b[A\n",
      " 10%|\u001b[38;2;30;71;6m████████▎                                                                        \u001b[0m| 96/937 [00:00<00:08, 96.21it/s]\u001b[0m\u001b[A\n",
      " 11%|\u001b[38;2;30;71;6m█████████                                                                       \u001b[0m| 106/937 [00:01<00:08, 96.73it/s]\u001b[0m\u001b[A\n",
      " 12%|\u001b[38;2;30;71;6m█████████▉                                                                      \u001b[0m| 117/937 [00:01<00:08, 98.55it/s]\u001b[0m\u001b[A\n",
      " 14%|\u001b[38;2;30;71;6m██████████▊                                                                    \u001b[0m| 128/937 [00:01<00:07, 101.81it/s]\u001b[0m\u001b[A\n",
      " 15%|\u001b[38;2;30;71;6m████████████                                                                   \u001b[0m| 143/937 [00:01<00:06, 114.27it/s]\u001b[0m\u001b[A\n",
      " 17%|\u001b[38;2;30;71;6m█████████████▏                                                                 \u001b[0m| 157/937 [00:01<00:06, 119.87it/s]\u001b[0m\u001b[A\n",
      " 18%|\u001b[38;2;30;71;6m██████████████▎                                                                \u001b[0m| 170/937 [00:01<00:06, 118.38it/s]\u001b[0m\u001b[A\n",
      " 20%|\u001b[38;2;30;71;6m███████████████▌                                                               \u001b[0m| 185/937 [00:01<00:05, 127.31it/s]\u001b[0m\u001b[A\n",
      " 21%|\u001b[38;2;30;71;6m████████████████▋                                                              \u001b[0m| 198/937 [00:01<00:05, 127.63it/s]\u001b[0m\u001b[A\n",
      " 23%|\u001b[38;2;30;71;6m█████████████████▉                                                             \u001b[0m| 213/937 [00:01<00:05, 132.53it/s]\u001b[0m\u001b[A\n",
      " 24%|\u001b[38;2;30;71;6m███████████████████▏                                                           \u001b[0m| 227/937 [00:01<00:05, 132.90it/s]\u001b[0m\u001b[A\n",
      " 26%|\u001b[38;2;30;71;6m████████████████████▍                                                          \u001b[0m| 242/937 [00:02<00:05, 135.85it/s]\u001b[0m\u001b[A\n",
      " 27%|\u001b[38;2;30;71;6m█████████████████████▌                                                         \u001b[0m| 256/937 [00:02<00:05, 136.09it/s]\u001b[0m\u001b[A\n",
      " 29%|\u001b[38;2;30;71;6m██████████████████████▊                                                        \u001b[0m| 271/937 [00:02<00:04, 137.99it/s]\u001b[0m\u001b[A\n",
      " 30%|\u001b[38;2;30;71;6m████████████████████████                                                       \u001b[0m| 285/937 [00:02<00:04, 134.28it/s]\u001b[0m\u001b[A\n",
      " 32%|\u001b[38;2;30;71;6m█████████████████████████▏                                                     \u001b[0m| 299/937 [00:02<00:04, 133.10it/s]\u001b[0m\u001b[A\n",
      " 34%|\u001b[38;2;30;71;6m██████████████████████████▍                                                    \u001b[0m| 314/937 [00:02<00:04, 136.60it/s]\u001b[0m\u001b[A\n",
      " 35%|\u001b[38;2;30;71;6m███████████████████████████▋                                                   \u001b[0m| 328/937 [00:02<00:04, 134.48it/s]\u001b[0m\u001b[A\n",
      " 36%|\u001b[38;2;30;71;6m████████████████████████████▊                                                  \u001b[0m| 342/937 [00:02<00:04, 134.54it/s]\u001b[0m\u001b[A\n",
      " 38%|\u001b[38;2;30;71;6m██████████████████████████████                                                 \u001b[0m| 356/937 [00:02<00:04, 133.82it/s]\u001b[0m\u001b[A\n",
      " 40%|\u001b[38;2;30;71;6m███████████████████████████████▎                                               \u001b[0m| 371/937 [00:03<00:04, 136.37it/s]\u001b[0m\u001b[A\n",
      " 41%|\u001b[38;2;30;71;6m████████████████████████████████▍                                              \u001b[0m| 385/937 [00:03<00:04, 133.88it/s]\u001b[0m\u001b[A\n",
      " 43%|\u001b[38;2;30;71;6m█████████████████████████████████▋                                             \u001b[0m| 399/937 [00:03<00:03, 135.40it/s]\u001b[0m\u001b[A\n",
      " 44%|\u001b[38;2;30;71;6m██████████████████████████████████▊                                            \u001b[0m| 413/937 [00:03<00:03, 133.56it/s]\u001b[0m\u001b[A\n",
      " 46%|\u001b[38;2;30;71;6m████████████████████████████████████                                           \u001b[0m| 427/937 [00:03<00:03, 132.17it/s]\u001b[0m\u001b[A\n",
      " 47%|\u001b[38;2;30;71;6m█████████████████████████████████████▏                                         \u001b[0m| 441/937 [00:03<00:03, 128.40it/s]\u001b[0m\u001b[A\n",
      " 48%|\u001b[38;2;30;71;6m██████████████████████████████████████▎                                        \u001b[0m| 454/937 [00:03<00:03, 126.04it/s]\u001b[0m\u001b[A\n",
      " 50%|\u001b[38;2;30;71;6m███████████████████████████████████████▎                                       \u001b[0m| 467/937 [00:03<00:03, 122.43it/s]\u001b[0m\u001b[A\n",
      " 51%|\u001b[38;2;30;71;6m████████████████████████████████████████▍                                      \u001b[0m| 480/937 [00:03<00:03, 120.43it/s]\u001b[0m\u001b[A\n",
      " 53%|\u001b[38;2;30;71;6m█████████████████████████████████████████▌                                     \u001b[0m| 493/937 [00:04<00:03, 121.32it/s]\u001b[0m\u001b[A\n",
      " 54%|\u001b[38;2;30;71;6m██████████████████████████████████████████▋                                    \u001b[0m| 506/937 [00:04<00:03, 122.10it/s]\u001b[0m\u001b[A\n",
      " 55%|\u001b[38;2;30;71;6m███████████████████████████████████████████▊                                   \u001b[0m| 519/937 [00:04<00:03, 112.50it/s]\u001b[0m\u001b[A\n",
      " 57%|\u001b[38;2;30;71;6m████████████████████████████████████████████▊                                  \u001b[0m| 531/937 [00:04<00:03, 113.91it/s]\u001b[0m\u001b[A\n",
      " 58%|\u001b[38;2;30;71;6m█████████████████████████████████████████████▊                                 \u001b[0m| 544/937 [00:04<00:03, 117.27it/s]\u001b[0m\u001b[A\n",
      " 59%|\u001b[38;2;30;71;6m██████████████████████████████████████████████▉                                \u001b[0m| 556/937 [00:04<00:03, 115.13it/s]\u001b[0m\u001b[A\n",
      " 61%|\u001b[38;2;30;71;6m███████████████████████████████████████████████▉                               \u001b[0m| 569/937 [00:04<00:03, 118.35it/s]\u001b[0m\u001b[A\n",
      " 62%|\u001b[38;2;30;71;6m████████████████████████████████████████████████▉                              \u001b[0m| 581/937 [00:04<00:03, 117.72it/s]\u001b[0m\u001b[A\n",
      " 63%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████▉                             \u001b[0m| 593/937 [00:04<00:02, 117.41it/s]\u001b[0m\u001b[A\n",
      " 65%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████                            \u001b[0m| 605/937 [00:04<00:02, 112.96it/s]\u001b[0m\u001b[A\n",
      " 66%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████                           \u001b[0m| 617/937 [00:05<00:02, 110.88it/s]\u001b[0m\u001b[A\n",
      " 67%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████                          \u001b[0m| 629/937 [00:05<00:02, 107.47it/s]\u001b[0m\u001b[A\n",
      " 68%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████▉                         \u001b[0m| 640/937 [00:05<00:02, 103.33it/s]\u001b[0m\u001b[A\n",
      " 69%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████▌                        \u001b[0m| 651/937 [00:05<00:02, 99.76it/s]\u001b[0m\u001b[A\n",
      " 71%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████▊                       \u001b[0m| 662/937 [00:05<00:02, 100.82it/s]\u001b[0m\u001b[A\n",
      " 72%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████▍                      \u001b[0m| 673/937 [00:05<00:02, 99.50it/s]\u001b[0m\u001b[A\n",
      " 73%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████▋                     \u001b[0m| 684/937 [00:05<00:02, 101.20it/s]\u001b[0m\u001b[A\n",
      " 74%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████▎                    \u001b[0m| 695/937 [00:05<00:02, 99.55it/s]\u001b[0m\u001b[A\n",
      " 75%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████▏                   \u001b[0m| 705/937 [00:06<00:02, 97.17it/s]\u001b[0m\u001b[A\n",
      " 76%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████                   \u001b[0m| 715/937 [00:06<00:02, 95.48it/s]\u001b[0m\u001b[A\n",
      " 77%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████▉                  \u001b[0m| 725/937 [00:06<00:02, 93.50it/s]\u001b[0m\u001b[A\n",
      " 78%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████▊                 \u001b[0m| 735/937 [00:06<00:02, 93.35it/s]\u001b[0m\u001b[A\n",
      " 80%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████▌                \u001b[0m| 745/937 [00:06<00:02, 92.49it/s]\u001b[0m\u001b[A\n",
      " 81%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████▍               \u001b[0m| 755/937 [00:06<00:01, 92.86it/s]\u001b[0m\u001b[A\n",
      " 82%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████▎              \u001b[0m| 765/937 [00:06<00:01, 94.64it/s]\u001b[0m\u001b[A\n",
      " 83%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████▏             \u001b[0m| 775/937 [00:06<00:01, 92.37it/s]\u001b[0m\u001b[A\n",
      " 84%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████             \u001b[0m| 785/937 [00:06<00:01, 92.17it/s]\u001b[0m\u001b[A\n",
      " 85%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████▉            \u001b[0m| 795/937 [00:06<00:01, 92.02it/s]\u001b[0m\u001b[A\n",
      " 86%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████▊           \u001b[0m| 806/937 [00:07<00:01, 94.93it/s]\u001b[0m\u001b[A\n",
      " 87%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████████▋          \u001b[0m| 816/937 [00:07<00:01, 93.47it/s]\u001b[0m\u001b[A\n",
      " 88%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████▌         \u001b[0m| 826/937 [00:07<00:01, 92.21it/s]\u001b[0m\u001b[A\n",
      " 89%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████▍        \u001b[0m| 836/937 [00:07<00:01, 93.48it/s]\u001b[0m\u001b[A\n",
      " 90%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████████▏       \u001b[0m| 846/937 [00:07<00:00, 92.69it/s]\u001b[0m\u001b[A\n",
      " 91%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████████████       \u001b[0m| 856/937 [00:07<00:00, 86.65it/s]\u001b[0m\u001b[A\n",
      " 92%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████████████▊      \u001b[0m| 865/937 [00:07<00:00, 87.17it/s]\u001b[0m\u001b[A\n",
      " 93%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████████▋     \u001b[0m| 875/937 [00:07<00:00, 88.87it/s]\u001b[0m\u001b[A\n",
      " 94%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████████▍    \u001b[0m| 884/937 [00:07<00:00, 88.69it/s]\u001b[0m\u001b[A\n",
      " 95%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████████████▎   \u001b[0m| 894/937 [00:08<00:00, 89.28it/s]\u001b[0m\u001b[A\n",
      " 96%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████████████████   \u001b[0m| 903/937 [00:08<00:00, 88.75it/s]\u001b[0m\u001b[A\n",
      " 97%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████████████████▉  \u001b[0m| 913/937 [00:08<00:00, 89.97it/s]\u001b[0m\u001b[A\n",
      " 99%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████████████▊ \u001b[0m| 923/937 [00:08<00:00, 89.99it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████████████\u001b[0m| 937/937 [00:08<00:00, 109.44it/s]\u001b[0m\u001b[A\n",
      "\u001b[32m2024-11-16 14:37:13.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mEpoch 1 train 0.3635 test 0.3697 metric ['0.8643']\u001b[0m\n",
      " 67%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████                            \u001b[0m| 2/3 [00:16<00:08,  8.42s/it]\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                          \u001b[0m| 0/937 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "  1%|\u001b[38;2;30;71;6m▊                                                                                 \u001b[0m| 9/937 [00:00<00:11, 83.46it/s]\u001b[0m\u001b[A\n",
      "  2%|\u001b[38;2;30;71;6m█▌                                                                               \u001b[0m| 18/937 [00:00<00:10, 86.27it/s]\u001b[0m\u001b[A\n",
      "  3%|\u001b[38;2;30;71;6m██▎                                                                              \u001b[0m| 27/937 [00:00<00:10, 85.16it/s]\u001b[0m\u001b[A\n",
      "  4%|\u001b[38;2;30;71;6m███                                                                              \u001b[0m| 36/937 [00:00<00:10, 84.73it/s]\u001b[0m\u001b[A\n",
      "  5%|\u001b[38;2;30;71;6m███▉                                                                             \u001b[0m| 45/937 [00:00<00:10, 84.55it/s]\u001b[0m\u001b[A\n",
      "  6%|\u001b[38;2;30;71;6m████▊                                                                            \u001b[0m| 55/937 [00:00<00:09, 88.31it/s]\u001b[0m\u001b[A\n",
      "  7%|\u001b[38;2;30;71;6m█████▌                                                                           \u001b[0m| 65/937 [00:00<00:09, 89.65it/s]\u001b[0m\u001b[A\n",
      "  8%|\u001b[38;2;30;71;6m██████▍                                                                          \u001b[0m| 75/937 [00:00<00:09, 90.85it/s]\u001b[0m\u001b[A\n",
      "  9%|\u001b[38;2;30;71;6m███████▎                                                                         \u001b[0m| 85/937 [00:00<00:09, 88.51it/s]\u001b[0m\u001b[A\n",
      " 10%|\u001b[38;2;30;71;6m████████▏                                                                        \u001b[0m| 95/937 [00:01<00:09, 89.02it/s]\u001b[0m\u001b[A\n",
      " 11%|\u001b[38;2;30;71;6m████████▉                                                                       \u001b[0m| 104/937 [00:01<00:09, 88.43it/s]\u001b[0m\u001b[A\n",
      " 12%|\u001b[38;2;30;71;6m█████████▋                                                                      \u001b[0m| 114/937 [00:01<00:09, 90.04it/s]\u001b[0m\u001b[A\n",
      " 13%|\u001b[38;2;30;71;6m██████████▌                                                                     \u001b[0m| 124/937 [00:01<00:09, 88.81it/s]\u001b[0m\u001b[A\n",
      " 14%|\u001b[38;2;30;71;6m███████████▍                                                                    \u001b[0m| 134/937 [00:01<00:08, 90.24it/s]\u001b[0m\u001b[A\n",
      " 15%|\u001b[38;2;30;71;6m████████████▎                                                                   \u001b[0m| 144/937 [00:01<00:08, 89.56it/s]\u001b[0m\u001b[A\n",
      " 16%|\u001b[38;2;30;71;6m█████████████▏                                                                  \u001b[0m| 154/937 [00:01<00:08, 90.09it/s]\u001b[0m\u001b[A\n",
      " 18%|\u001b[38;2;30;71;6m██████████████                                                                  \u001b[0m| 164/937 [00:01<00:08, 88.28it/s]\u001b[0m\u001b[A\n",
      " 18%|\u001b[38;2;30;71;6m██████████████▊                                                                 \u001b[0m| 173/937 [00:01<00:08, 87.95it/s]\u001b[0m\u001b[A\n",
      " 19%|\u001b[38;2;30;71;6m███████████████▌                                                                \u001b[0m| 182/937 [00:02<00:08, 86.57it/s]\u001b[0m\u001b[A\n",
      " 20%|\u001b[38;2;30;71;6m████████████████▎                                                               \u001b[0m| 191/937 [00:02<00:08, 87.13it/s]\u001b[0m\u001b[A\n",
      " 21%|\u001b[38;2;30;71;6m█████████████████                                                               \u001b[0m| 200/937 [00:02<00:08, 87.56it/s]\u001b[0m\u001b[A\n",
      " 22%|\u001b[38;2;30;71;6m█████████████████▊                                                              \u001b[0m| 209/937 [00:02<00:08, 87.50it/s]\u001b[0m\u001b[A\n",
      " 23%|\u001b[38;2;30;71;6m██████████████████▌                                                             \u001b[0m| 218/937 [00:02<00:08, 80.41it/s]\u001b[0m\u001b[A\n",
      " 24%|\u001b[38;2;30;71;6m███████████████████▍                                                            \u001b[0m| 227/937 [00:02<00:08, 79.40it/s]\u001b[0m\u001b[A\n",
      " 25%|\u001b[38;2;30;71;6m████████████████████▏                                                           \u001b[0m| 236/937 [00:02<00:08, 80.70it/s]\u001b[0m\u001b[A\n",
      " 26%|\u001b[38;2;30;71;6m████████████████████▉                                                           \u001b[0m| 245/937 [00:02<00:08, 81.29it/s]\u001b[0m\u001b[A\n",
      " 27%|\u001b[38;2;30;71;6m█████████████████████▋                                                          \u001b[0m| 254/937 [00:02<00:08, 83.04it/s]\u001b[0m\u001b[A\n",
      " 28%|\u001b[38;2;30;71;6m██████████████████████▌                                                         \u001b[0m| 264/937 [00:03<00:07, 85.70it/s]\u001b[0m\u001b[A\n",
      " 29%|\u001b[38;2;30;71;6m███████████████████████▎                                                        \u001b[0m| 273/937 [00:03<00:08, 82.39it/s]\u001b[0m\u001b[A\n",
      " 30%|\u001b[38;2;30;71;6m████████████████████████                                                        \u001b[0m| 282/937 [00:03<00:07, 83.41it/s]\u001b[0m\u001b[A\n",
      " 31%|\u001b[38;2;30;71;6m████████████████████████▊                                                       \u001b[0m| 291/937 [00:03<00:08, 80.67it/s]\u001b[0m\u001b[A\n",
      " 32%|\u001b[38;2;30;71;6m█████████████████████████▌                                                      \u001b[0m| 300/937 [00:03<00:07, 80.42it/s]\u001b[0m\u001b[A\n",
      " 33%|\u001b[38;2;30;71;6m██████████████████████████▍                                                     \u001b[0m| 309/937 [00:03<00:07, 80.65it/s]\u001b[0m\u001b[A\n",
      " 34%|\u001b[38;2;30;71;6m███████████████████████████▏                                                    \u001b[0m| 319/937 [00:03<00:07, 83.02it/s]\u001b[0m\u001b[A\n",
      " 35%|\u001b[38;2;30;71;6m████████████████████████████                                                    \u001b[0m| 328/937 [00:03<00:07, 84.43it/s]\u001b[0m\u001b[A\n",
      " 36%|\u001b[38;2;30;71;6m████████████████████████████▊                                                   \u001b[0m| 337/937 [00:03<00:07, 83.98it/s]\u001b[0m\u001b[A\n",
      " 37%|\u001b[38;2;30;71;6m█████████████████████████████▌                                                  \u001b[0m| 346/937 [00:04<00:07, 83.11it/s]\u001b[0m\u001b[A\n",
      " 38%|\u001b[38;2;30;71;6m██████████████████████████████▎                                                 \u001b[0m| 355/937 [00:04<00:06, 83.81it/s]\u001b[0m\u001b[A\n",
      " 39%|\u001b[38;2;30;71;6m███████████████████████████████                                                 \u001b[0m| 364/937 [00:04<00:06, 82.19it/s]\u001b[0m\u001b[A\n",
      " 40%|\u001b[38;2;30;71;6m███████████████████████████████▊                                                \u001b[0m| 373/937 [00:04<00:06, 80.65it/s]\u001b[0m\u001b[A\n",
      " 41%|\u001b[38;2;30;71;6m████████████████████████████████▌                                               \u001b[0m| 382/937 [00:04<00:06, 79.34it/s]\u001b[0m\u001b[A\n",
      " 42%|\u001b[38;2;30;71;6m█████████████████████████████████▍                                              \u001b[0m| 391/937 [00:04<00:06, 79.54it/s]\u001b[0m\u001b[A\n",
      " 43%|\u001b[38;2;30;71;6m██████████████████████████████████▏                                             \u001b[0m| 400/937 [00:04<00:06, 81.03it/s]\u001b[0m\u001b[A\n",
      " 44%|\u001b[38;2;30;71;6m██████████████████████████████████▉                                             \u001b[0m| 409/937 [00:04<00:06, 80.56it/s]\u001b[0m\u001b[A\n",
      " 45%|\u001b[38;2;30;71;6m███████████████████████████████████▋                                            \u001b[0m| 418/937 [00:04<00:06, 81.90it/s]\u001b[0m\u001b[A\n",
      " 46%|\u001b[38;2;30;71;6m████████████████████████████████████▍                                           \u001b[0m| 427/937 [00:05<00:06, 84.04it/s]\u001b[0m\u001b[A\n",
      " 47%|\u001b[38;2;30;71;6m█████████████████████████████████████▏                                          \u001b[0m| 436/937 [00:05<00:06, 82.57it/s]\u001b[0m\u001b[A\n",
      " 47%|\u001b[38;2;30;71;6m█████████████████████████████████████▉                                          \u001b[0m| 445/937 [00:05<00:06, 80.75it/s]\u001b[0m\u001b[A\n",
      " 48%|\u001b[38;2;30;71;6m██████████████████████████████████████▊                                         \u001b[0m| 454/937 [00:05<00:05, 80.65it/s]\u001b[0m\u001b[A\n",
      " 49%|\u001b[38;2;30;71;6m███████████████████████████████████████▌                                        \u001b[0m| 463/937 [00:05<00:05, 81.75it/s]\u001b[0m\u001b[A\n",
      " 50%|\u001b[38;2;30;71;6m████████████████████████████████████████▎                                       \u001b[0m| 472/937 [00:05<00:05, 79.22it/s]\u001b[0m\u001b[A\n",
      " 51%|\u001b[38;2;30;71;6m████████████████████████████████████████▉                                       \u001b[0m| 480/937 [00:05<00:06, 74.39it/s]\u001b[0m\u001b[A\n",
      " 52%|\u001b[38;2;30;71;6m█████████████████████████████████████████▋                                      \u001b[0m| 488/937 [00:05<00:05, 74.90it/s]\u001b[0m\u001b[A\n",
      " 53%|\u001b[38;2;30;71;6m██████████████████████████████████████████▍                                     \u001b[0m| 497/937 [00:05<00:05, 77.45it/s]\u001b[0m\u001b[A\n",
      " 54%|\u001b[38;2;30;71;6m███████████████████████████████████████████                                     \u001b[0m| 505/937 [00:06<00:05, 78.06it/s]\u001b[0m\u001b[A\n",
      " 55%|\u001b[38;2;30;71;6m███████████████████████████████████████████▉                                    \u001b[0m| 514/937 [00:06<00:05, 79.22it/s]\u001b[0m\u001b[A\n",
      " 56%|\u001b[38;2;30;71;6m████████████████████████████████████████████▌                                   \u001b[0m| 522/937 [00:06<00:05, 77.86it/s]\u001b[0m\u001b[A\n",
      " 57%|\u001b[38;2;30;71;6m█████████████████████████████████████████████▎                                  \u001b[0m| 531/937 [00:06<00:05, 79.42it/s]\u001b[0m\u001b[A\n",
      " 58%|\u001b[38;2;30;71;6m██████████████████████████████████████████████                                  \u001b[0m| 540/937 [00:06<00:04, 80.77it/s]\u001b[0m\u001b[A\n",
      " 59%|\u001b[38;2;30;71;6m██████████████████████████████████████████████▊                                 \u001b[0m| 549/937 [00:06<00:04, 80.48it/s]\u001b[0m\u001b[A\n",
      " 60%|\u001b[38;2;30;71;6m███████████████████████████████████████████████▋                                \u001b[0m| 558/937 [00:06<00:04, 79.71it/s]\u001b[0m\u001b[A\n",
      " 61%|\u001b[38;2;30;71;6m████████████████████████████████████████████████▍                               \u001b[0m| 567/937 [00:06<00:04, 80.35it/s]\u001b[0m\u001b[A\n",
      " 61%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████▏                              \u001b[0m| 576/937 [00:06<00:04, 78.55it/s]\u001b[0m\u001b[A\n",
      " 62%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████▊                              \u001b[0m| 584/937 [00:07<00:04, 78.90it/s]\u001b[0m\u001b[A\n",
      " 63%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████▌                             \u001b[0m| 592/937 [00:07<00:04, 77.81it/s]\u001b[0m\u001b[A\n",
      " 64%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████▏                            \u001b[0m| 600/937 [00:07<00:04, 76.88it/s]\u001b[0m\u001b[A\n",
      " 65%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████▉                            \u001b[0m| 608/937 [00:07<00:04, 76.03it/s]\u001b[0m\u001b[A\n",
      " 66%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████▌                           \u001b[0m| 616/937 [00:07<00:04, 75.49it/s]\u001b[0m\u001b[A\n",
      " 67%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████▎                          \u001b[0m| 625/937 [00:07<00:04, 77.28it/s]\u001b[0m\u001b[A\n",
      " 68%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████▏                         \u001b[0m| 634/937 [00:07<00:03, 78.45it/s]\u001b[0m\u001b[A\n",
      " 69%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████▊                         \u001b[0m| 642/937 [00:07<00:03, 77.93it/s]\u001b[0m\u001b[A\n",
      " 69%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████▍                        \u001b[0m| 650/937 [00:07<00:03, 77.80it/s]\u001b[0m\u001b[A\n",
      " 70%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████▏                       \u001b[0m| 658/937 [00:08<00:03, 76.52it/s]\u001b[0m\u001b[A\n",
      " 71%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████▊                       \u001b[0m| 666/937 [00:08<00:03, 75.91it/s]\u001b[0m\u001b[A\n",
      " 72%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████▌                      \u001b[0m| 674/937 [00:08<00:03, 74.37it/s]\u001b[0m\u001b[A\n",
      " 73%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████▎                     \u001b[0m| 683/937 [00:08<00:03, 76.73it/s]\u001b[0m\u001b[A\n",
      " 74%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████▉                     \u001b[0m| 691/937 [00:08<00:03, 76.02it/s]\u001b[0m\u001b[A\n",
      " 75%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████▋                    \u001b[0m| 699/937 [00:08<00:03, 75.16it/s]\u001b[0m\u001b[A\n",
      " 75%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████▎                   \u001b[0m| 707/937 [00:08<00:03, 74.71it/s]\u001b[0m\u001b[A\n",
      " 76%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████                   \u001b[0m| 715/937 [00:08<00:02, 75.19it/s]\u001b[0m\u001b[A\n",
      " 77%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████▊                  \u001b[0m| 724/937 [00:08<00:02, 76.63it/s]\u001b[0m\u001b[A\n",
      " 78%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████▍                 \u001b[0m| 732/937 [00:08<00:02, 75.51it/s]\u001b[0m\u001b[A\n",
      " 79%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████▏                \u001b[0m| 740/937 [00:09<00:02, 73.98it/s]\u001b[0m\u001b[A\n",
      " 80%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████▊                \u001b[0m| 748/937 [00:09<00:02, 73.30it/s]\u001b[0m\u001b[A\n",
      " 81%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████▌               \u001b[0m| 756/937 [00:09<00:02, 72.89it/s]\u001b[0m\u001b[A\n",
      " 82%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████▎              \u001b[0m| 765/937 [00:09<00:02, 75.01it/s]\u001b[0m\u001b[A\n",
      " 82%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████▉              \u001b[0m| 773/937 [00:09<00:02, 74.97it/s]\u001b[0m\u001b[A\n",
      " 83%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████▋             \u001b[0m| 781/937 [00:09<00:02, 73.97it/s]\u001b[0m\u001b[A\n",
      " 84%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████▎            \u001b[0m| 789/937 [00:09<00:02, 72.75it/s]\u001b[0m\u001b[A\n",
      " 85%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████            \u001b[0m| 797/937 [00:09<00:01, 73.33it/s]\u001b[0m\u001b[A\n",
      " 86%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████▋           \u001b[0m| 805/937 [00:09<00:01, 72.91it/s]\u001b[0m\u001b[A\n",
      " 87%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████████▍          \u001b[0m| 813/937 [00:10<00:01, 72.12it/s]\u001b[0m\u001b[A\n",
      " 88%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████          \u001b[0m| 821/937 [00:10<00:01, 72.11it/s]\u001b[0m\u001b[A\n",
      " 88%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████▊         \u001b[0m| 829/937 [00:10<00:01, 73.19it/s]\u001b[0m\u001b[A\n",
      " 89%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████▍        \u001b[0m| 837/937 [00:10<00:01, 73.41it/s]\u001b[0m\u001b[A\n",
      " 90%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████████▏       \u001b[0m| 845/937 [00:10<00:01, 73.05it/s]\u001b[0m\u001b[A\n",
      " 91%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████████▊       \u001b[0m| 853/937 [00:10<00:01, 72.53it/s]\u001b[0m\u001b[A\n",
      " 92%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████████████▌      \u001b[0m| 861/937 [00:10<00:01, 73.09it/s]\u001b[0m\u001b[A\n",
      " 93%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████████▏     \u001b[0m| 869/937 [00:10<00:00, 71.17it/s]\u001b[0m\u001b[A\n",
      " 94%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████████▉     \u001b[0m| 877/937 [00:11<00:00, 67.34it/s]\u001b[0m\u001b[A\n",
      " 94%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████████▍    \u001b[0m| 884/937 [00:11<00:00, 66.75it/s]\u001b[0m\u001b[A\n",
      " 95%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████████████    \u001b[0m| 891/937 [00:11<00:00, 67.31it/s]\u001b[0m\u001b[A\n",
      " 96%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████████████▊   \u001b[0m| 900/937 [00:11<00:00, 70.97it/s]\u001b[0m\u001b[A\n",
      " 97%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████████████████▌  \u001b[0m| 908/937 [00:11<00:00, 71.69it/s]\u001b[0m\u001b[A\n",
      " 98%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████████████▏ \u001b[0m| 916/937 [00:11<00:00, 71.94it/s]\u001b[0m\u001b[A\n",
      " 99%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████████████▉ \u001b[0m| 924/937 [00:11<00:00, 70.87it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████████████████\u001b[0m| 937/937 [00:11<00:00, 79.05it/s]\u001b[0m\u001b[A\n",
      "\u001b[32m2024-11-16 14:37:26.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m189\u001b[0m - \u001b[1mEpoch 2 train 0.3226 test 0.3713 metric ['0.8737']\u001b[0m\n",
      "\u001b[32m2024-11-16 14:37:26.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m232\u001b[0m - \u001b[1mbest loss: 0.3697, current loss 0.3713.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 3/3 [00:29<00:00,  9.74s/it]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer.loop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will have the latest model at trainer.model, or just use the old model (which is the same)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a look at the settings.earlystop_kwargs, you can see that save is by default false. If you change this to true, the trainer would have kept track of the best model so far and saved it in between. Because this can take up additional time and in a learning setting like we are in we typically dont really want to save the model for later use, we dont need it here.\n",
    "\n",
    "However, in a real life setting you probably want the best model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'save': False, 'verbose': True, 'patience': 10}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings.earlystop_kwargs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save it manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modeldir exists: True\n"
     ]
    }
   ],
   "source": [
    "model_dir = Path(\"../../models\").resolve()\n",
    "print(f'modeldir exists: {model_dir.exists()}')\n",
    "modelpath = model_dir / \"trained_model\"\n",
    "torch.save(model, modelpath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case you would have set the earlystop.save to true like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = TrainerSettings(\n",
    "    epochs=10,\n",
    "    metrics=[accuracy],\n",
    "    logdir=log_dir,\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD],\n",
    "    earlystop_kwargs={'save': True, 'verbose': True, 'patience': 10}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainer would have saved checkpoints of the last best model. You can obtain the location of the checkpoint with `trainer.early_stopping.path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/dilek/desktop/Advanced_AI_Applications_WS24-25_MADS_HSRW/notebooks/1_pytorch_intro/logs/20241116-143649/checkpoint.pt')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.early_stopping.path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "# note that I would expect the loaded model to run on mps, but that doesnt work as expected\n",
    "if device == \"mps\":\n",
    "    device = \"cpu\"\n",
    "print(f\"using {device}\")\n",
    "loaded_model = torch.load(modelpath, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "for param in loaded_model.parameters():\n",
    "    print(param.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a batch $X$, $y$ and make a prediction $\\hat{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8021, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = loaded_model(X.to(device))\n",
    "loss_fn(yhat, y.to(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy:\n",
    "- for every example we have 10 numbers\n",
    "- the location with the highest value is the prediction\n",
    "- we can get the index with `argmax` over dimension 1\n",
    "- we compare that index with the original number\n",
    "- This gives us a count of all the correct predictions\n",
    "- dividing that through the total length gives us the accuracy percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.5625"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = (yhat.argmax(dim=1) == y.to(device)).sum() / len(y.to(device))\n",
    "acc.item() * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is the accuracy for a single batch! \n",
    "Get another batch by running next() in the cell above, and calculate the accuracy again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1462, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(testloader))\n",
    "yhat = loaded_model(X.to(device))\n",
    "loss_fn(yhat, y.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.75"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = (yhat.argmax(dim=1) == y.to(device)).sum() / len(y.to(device))\n",
    "acc.item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3655, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(iter(testloader))\n",
    "yhat = loaded_model(X.to(device))\n",
    "loss_fn(yhat, y.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.625"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = (yhat.argmax(dim=1) == y.to(device)).sum() / len(y.to(device))\n",
    "acc.item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "45c41bdaf5373703b03bba2d9bd89c97dc8ee5add9f1112e039ff04603b8e2ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
