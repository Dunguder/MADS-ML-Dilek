{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from plotly import graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default = 'plotly_mimetype+notebook'\n",
    "\n",
    "import visualize\n",
    "DELETE = True # to delete the tunedir at the end of the notebook\n",
    "start = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a general reference notebook to explore the use of ray tuner.\n",
    "First, we define some global variables. This makes it easier to change the parameters for the full notebook at once and run everything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 5\n",
    "N_EXPERIMENTS = 18"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train function and config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some dicts to log the results of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = {}\n",
    "best_config = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a training function. This is also implemented in the mltrainer, but I put it here to show you how the details work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, trainstreamer, lossfn, optimizer, steps):\n",
    "    model.train()\n",
    "    train_loss: float = 0.0\n",
    "    for _ in range(steps):\n",
    "        x, y = next(trainstreamer)\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(x)\n",
    "        loss = lossfn(yhat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We validate on the validation set and return the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, validstreamer, lossfn, metric, steps):\n",
    "    model.eval()\n",
    "    valid_loss: float = 0.0\n",
    "    acc: float = 0.0\n",
    "    with torch.no_grad():\n",
    "        for _ in range(steps):\n",
    "            x, y = next(validstreamer)\n",
    "            yhat = model(x)\n",
    "            loss = lossfn(yhat, y)\n",
    "            valid_loss += loss.item()\n",
    "            acc += metric(y, yhat)\n",
    "    acc /= steps\n",
    "    return valid_loss, acc.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the data requires a bit extra care. Because we will run experiments in parallel on all the cpu's available, we well use FileLock to make sure that loading the data does not conflict.\n",
    "\n",
    "Note we import functions inside the function we will later on pass to ray. This is because ray will serialize the function and send it to the workers. If we import the functions outside the function, the workers will not have access to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tune_dir):\n",
    "    from filelock import FileLock\n",
    "    from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "    from mltrainer.preprocessors import PaddedPreprocessor\n",
    "    from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "    with FileLock(tune_dir / \".lock\"):\n",
    "        # we lock the datadir to avoid parallel instances trying to\n",
    "        # access the datadir\n",
    "        preprocessor = PaddedPreprocessor()\n",
    "        gesturesdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "        streamers = gesturesdatasetfactory.create_datastreamer(\n",
    "            batchsize=32, preprocessor=preprocessor\n",
    "        )\n",
    "        train = streamers[\"train\"]\n",
    "        valid = streamers[\"valid\"]\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same GRU model we used last lesson. You might improve this in a few ways (eg consider adding skip layers, conv1d, etc) but for clarity, lets keep it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUmodel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: dict,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=config[\"input_size\"],\n",
    "            hidden_size=int(config[\"hidden_size\"]),\n",
    "            dropout=config[\"dropout\"],\n",
    "            batch_first=True,\n",
    "            num_layers=int(config[\"num_layers\"]),\n",
    "        )\n",
    "        self.linear = nn.Linear(int(config[\"hidden_size\"]), config[\"output_size\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        last_step = x[:, -1, :]\n",
    "        yhat = self.linear(last_step)\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have all the ingredients we need to run the tuner.\n",
    "We create a function that:\n",
    "- loads the data with a lock\n",
    "- creates the model\n",
    "- trains the model\n",
    "- validates the model\n",
    "- reports the results to ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(config: dict):\n",
    "    from mltrainer.metrics import Accuracy\n",
    "\n",
    "    # load data\n",
    "    train, valid = get_data(config[\"tune_dir\"])\n",
    "    trainsteps = len(train)\n",
    "    validsteps = len(valid)\n",
    "    trainstreamer = train.stream()\n",
    "    validstreamer = valid.stream()\n",
    "\n",
    "    # create model with config\n",
    "    model = GRUmodel(config)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    metric = Accuracy()\n",
    "\n",
    "    for _ in range(config[\"epochs\"]):\n",
    "        # train and validate\n",
    "        train_loss = train_fn(model, trainstreamer, loss_fn, optimizer, trainsteps)\n",
    "        valid_loss, accuracy = validate(model, validstreamer, loss_fn, metric, validsteps)\n",
    "\n",
    "        # report to ray\n",
    "        ray.train.report({\n",
    "            \"valid_loss\": valid_loss / validsteps,\n",
    "            \"train_loss\": train_loss / trainsteps,\n",
    "            \"accuracy\" : accuracy,\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this, to see if everything works as expected.\n",
    "Note that it typically does not make sense to use accelaration here; we will typically have 1 GPU, but 10 or 16 CPUS. We gain much more from parallelizing the experiments than we gain by running the model faster on a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-11 13:47:21.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\dilek\\.cache\\mads_datasets\\gestures\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████████████\u001b[0m| 2600/2600 [00:00<00:00, 3289.94it/s]\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████████████\u001b[0m| 651/651 [00:00<00:00, 3461.41it/s]\u001b[0m\n",
      "C:\\Users\\dilek\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\ray\\train\\_internal\\session.py:651: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tune_dir = Path(\"models/ray/\").resolve()\n",
    "\n",
    "config = {\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"dropout\": 0.1,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"epochs\": MAX_EPOCHS,\n",
    "    \"tune_dir\": tune_dir,\n",
    "}\n",
    "tune_model(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do a random search. \n",
    "\n",
    "First, we define the search space. We can specify specific values, but also distributions.\n",
    "For the hidden size, we will use randint, which will sample from a uniform distribution of integers.\n",
    "The same for the number of layers.\n",
    "\n",
    "The `tune.run` function runs the hypertuning. It will sample from the search space, and create a specific config for each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"dropout\": 0.05,\n",
    "    \"epochs\": MAX_EPOCHS,\n",
    "    \"hidden_size\": tune.randint(16, 512),\n",
    "    \"num_layers\": tune.randint(1, 8),\n",
    "    \"tune_dir\": tune_dir,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-11-11 13:56:58</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:05.30        </td></tr>\n",
       "<tr><td>Memory:      </td><td>14.5/15.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 18.0/20 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  num_layers</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_model_6c616_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           28</td><td style=\"text-align: right;\">           5</td></tr>\n",
       "<tr><td>tune_model_6c616_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          457</td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>tune_model_6c616_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          194</td><td style=\"text-align: right;\">           2</td></tr>\n",
       "<tr><td>tune_model_6c616_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          470</td><td style=\"text-align: right;\">           5</td></tr>\n",
       "<tr><td>tune_model_6c616_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          443</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>tune_model_6c616_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          270</td><td style=\"text-align: right;\">           7</td></tr>\n",
       "<tr><td>tune_model_6c616_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          358</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>tune_model_6c616_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          295</td><td style=\"text-align: right;\">           4</td></tr>\n",
       "<tr><td>tune_model_6c616_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          321</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>tune_model_6c616_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          446</td><td style=\"text-align: right;\">           6</td></tr>\n",
       "<tr><td>tune_model_6c616_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          162</td><td style=\"text-align: right;\">           2</td></tr>\n",
       "<tr><td>tune_model_6c616_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          252</td><td style=\"text-align: right;\">           6</td></tr>\n",
       "<tr><td>tune_model_6c616_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          454</td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>tune_model_6c616_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          157</td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>tune_model_6c616_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">          351</td><td style=\"text-align: right;\">           5</td></tr>\n",
       "<tr><td>tune_model_6c616_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           78</td><td style=\"text-align: right;\">           7</td></tr>\n",
       "<tr><td>tune_model_6c616_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           48</td><td style=\"text-align: right;\">           4</td></tr>\n",
       "<tr><td>tune_model_6c616_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           92</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/dilek/AppData/Local/Temp/ray/session_2024-11-11_13-48-56_314017_5152/artifacts/2024-11-11_13-56-52/tune_model_2024-11-11_13-56-52/driver_artifacts/tune_model_6c616_00008_8_hidden_size=321,num_layers=1_2024-11-11_13-56-52\\\\events.out.tfevents.1731329819.Delldanesi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\tensorboardX\\record_writer.py:58\u001b[0m, in \u001b[0;36mopen_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     57\u001b[0m prefix \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 58\u001b[0m factory \u001b[38;5;241m=\u001b[39m \u001b[43mREGISTERED_FACTORIES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m factory\u001b[38;5;241m.\u001b[39mopen(path)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'C'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 2\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalid_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtune_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_EXPERIMENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_iteration\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_EPOCHS\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m timer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mray_random\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m tic\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\ray\\tune\\tune.py:992\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mis_finished() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m--> 992\u001b[0m         \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m has_verbosity(Verbosity\u001b[38;5;241m.\u001b[39mV1_EXPERIMENT):\n\u001b[0;32m    994\u001b[0m             _report_progress(runner, progress_reporter)\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:685\u001b[0m, in \u001b[0;36mTuneController.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_add_actors()\n\u001b[0;32m    684\u001b[0m \u001b[38;5;66;03m# Handle one event\u001b[39;00m\n\u001b[1;32m--> 685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;66;03m# If there are no actors running, warn about potentially\u001b[39;00m\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;66;03m# insufficient resources\u001b[39;00m\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_manager\u001b[38;5;241m.\u001b[39mnum_live_actors:\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_resources_manager\u001b[38;5;241m.\u001b[39mon_no_available_trials(\n\u001b[0;32m    690\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_trials()\n\u001b[0;32m    691\u001b[0m         )\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\ray\\air\\execution\\_internal\\actor_manager.py:221\u001b[0m, in \u001b[0;36mRayActorManager.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    218\u001b[0m [future] \u001b[38;5;241m=\u001b[39m ready\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m actor_state_futures:\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_state_events\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_future\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m actor_task_futures:\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_task_events\u001b[38;5;241m.\u001b[39mresolve_future(future)\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py:118\u001b[0m, in \u001b[0;36mRayEventManager.resolve_future\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on_result:\n\u001b[1;32m--> 118\u001b[0m         \u001b[43mon_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\ray\\air\\execution\\_internal\\actor_manager.py:380\u001b[0m, in \u001b[0;36mRayActorManager._try_start_actors.<locals>.create_callbacks.<locals>.on_actor_start\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_actor_start\u001b[39m(result: Any):\n\u001b[1;32m--> 380\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_start_resolved\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtracked_actor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracked_actor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\ray\\air\\execution\\_internal\\actor_manager.py:242\u001b[0m, in \u001b[0;36mRayActorManager._actor_start_resolved\u001b[1;34m(self, tracked_actor, future)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracked_actors_to_state_futures[tracked_actor]\u001b[38;5;241m.\u001b[39mremove(future)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracked_actor\u001b[38;5;241m.\u001b[39m_on_start:\n\u001b[1;32m--> 242\u001b[0m     \u001b[43mtracked_actor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtracked_actor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\ray\\tune\\execution\\tune_controller.py:1131\u001b[0m, in \u001b[0;36mTuneController._actor_started\u001b[1;34m(self, tracked_actor, log)\u001b[0m\n\u001b[0;32m   1126\u001b[0m ray_actor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_manager\u001b[38;5;241m.\u001b[39m_live_actors_to_ray_actors_resources[\n\u001b[0;32m   1127\u001b[0m     tracked_actor\n\u001b[0;32m   1128\u001b[0m ][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1129\u001b[0m trial\u001b[38;5;241m.\u001b[39mset_ray_actor(ray_actor)\n\u001b[1;32m-> 1131\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trial_start\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trial_status(trial, Trial\u001b[38;5;241m.\u001b[39mRUNNING)\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mark_trial_to_checkpoint(trial)\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\ray\\tune\\callback.py:398\u001b[0m, in \u001b[0;36mCallbackList.on_trial_start\u001b[1;34m(self, **info)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minfo):\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callbacks:\n\u001b[1;32m--> 398\u001b[0m         \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trial_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\ray\\tune\\logger\\logger.py:147\u001b[0m, in \u001b[0;36mLoggerCallback.on_trial_start\u001b[1;34m(self, iteration, trials, trial, **info)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_start\u001b[39m(\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m, iteration: \u001b[38;5;28mint\u001b[39m, trials: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial\u001b[39m\u001b[38;5;124m\"\u001b[39m], trial: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minfo\n\u001b[0;32m    146\u001b[0m ):\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_trial_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\ray\\tune\\logger\\tensorboardx.py:202\u001b[0m, in \u001b[0;36mTBXLoggerCallback.log_trial_start\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_writer[trial]\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    201\u001b[0m trial\u001b[38;5;241m.\u001b[39minit_local_path()\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_writer[trial] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_summary_writer_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush_secs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\n\u001b[0;32m    204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_result[trial] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\tensorboardX\\writer.py:300\u001b[0m, in \u001b[0;36mSummaryWriter.__init__\u001b[1;34m(self, logdir, comment, purge_step, max_queue, flush_secs, filename_suffix, write_to_disk, log_dir, comet_config, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;66;03m# Initialize the file writers, but they can be cleared out on close\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m# and recreated later as needed.\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_writers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_file_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;66;03m# Create default bins for histograms, see generate_testdata.py in tensorflow/tensorboard\u001b[39;00m\n\u001b[0;32m    303\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1E-12\u001b[39m\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\tensorboardX\\writer.py:348\u001b[0m, in \u001b[0;36mSummaryWriter._get_file_writer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_writers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer \u001b[38;5;241m=\u001b[39m \u001b[43mFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmax_queue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_queue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mflush_secs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flush_secs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mfilename_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filename_suffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpurge_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_writer\u001b[38;5;241m.\u001b[39madd_event(\n\u001b[0;32m    355\u001b[0m             Event(step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpurge_step, file_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrain.Event:2\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\tensorboardX\\writer.py:104\u001b[0m, in \u001b[0;36mFileWriter.__init__\u001b[1;34m(self, logdir, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Sometimes PosixPath is passed in and we need to coerce it to\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# a string in all cases\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# TODO: See if we can remove this in the future if we are\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# actually the ones passing in a PosixPath\u001b[39;00m\n\u001b[0;32m    103\u001b[0m logdir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(logdir)\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_writer \u001b[38;5;241m=\u001b[39m \u001b[43mEventFileWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_queue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush_secs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename_suffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcleanup\u001b[39m():\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\tensorboardX\\event_file_writer.py:106\u001b[0m, in \u001b[0;36mEventFileWriter.__init__\u001b[1;34m(self, logdir, max_queue_size, flush_secs, filename_suffix)\u001b[0m\n\u001b[0;32m    104\u001b[0m directory_check(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logdir)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_queue \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mQueue(max_queue_size)\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ev_writer \u001b[38;5;241m=\u001b[39m \u001b[43mEventsWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename_suffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush_secs \u001b[38;5;241m=\u001b[39m flush_secs\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\tensorboardX\\event_file_writer.py:43\u001b[0m, in \u001b[0;36mEventsWriter.__init__\u001b[1;34m(self, file_prefix, filename_suffix)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_name \u001b[38;5;241m=\u001b[39m file_prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.out.tfevents.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime())[:\u001b[38;5;241m10\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m     41\u001b[0m     socket\u001b[38;5;241m.\u001b[39mgethostname() \u001b[38;5;241m+\u001b[39m filename_suffix\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outstanding_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_py_recordio_writer \u001b[38;5;241m=\u001b[39m \u001b[43mRecordWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Initialize an event instance.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event \u001b[38;5;241m=\u001b[39m event_pb2\u001b[38;5;241m.\u001b[39mEvent()\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\tensorboardX\\record_writer.py:182\u001b[0m, in \u001b[0;36mRecordWriter.__init__\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer \u001b[38;5;241m=\u001b[39m \u001b[43mopen_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\desktop\\Advanced_AI_Applications_WS24-25_MADS_HSRW\\.venv\\Lib\\site-packages\\tensorboardX\\record_writer.py:61\u001b[0m, in \u001b[0;36mopen_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m factory\u001b[38;5;241m.\u001b[39mopen(path)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/dilek/AppData/Local/Temp/ray/session_2024-11-11_13-48-56_314017_5152/artifacts/2024-11-11_13-56-52/tune_model_2024-11-11_13-56-52/driver_artifacts/tune_model_6c616_00008_8_hidden_size=321,num_layers=1_2024-11-11_13-56-52\\\\events.out.tfevents.1731329819.Delldanesi'"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "analysis = tune.run(\n",
    "    tune_model,\n",
    "    config=config,\n",
    "    metric=\"valid_loss\",\n",
    "    mode=\"min\",\n",
    "    local_dir=str(tune_dir),\n",
    "    num_samples=N_EXPERIMENTS,\n",
    "    stop={\"training_iteration\": MAX_EPOCHS},\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "timer[\"ray_random\"] = time.time() - tic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contour(df, x, y, z, start=0.90, end=1.0, size=0.01):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Contour(\n",
    "            z=df[z],\n",
    "            x=df[x],\n",
    "            y=df[y],\n",
    "            contours=dict(\n",
    "                coloring='heatmap',\n",
    "                showlabels=True,  # show labels on contours\n",
    "                start=start,       # start of the contour range\n",
    "                end=end,          # end of the contour range\n",
    "                size=size,\n",
    "            ),\n",
    "            colorscale=\"plasma\",\n",
    "            colorbar=dict(\n",
    "                title='Accuracy'\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df[x],\n",
    "            y=df[y],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                color='black',\n",
    "                size=8,\n",
    "                symbol='circle'\n",
    "            ),\n",
    "            customdata=df['accuracy'],  # Pass accuracy values for hover text\n",
    "            hovertemplate=(\n",
    "                'Hidden Size: %{x}<br>'\n",
    "                'Number of Layers: %{y}<br>'\n",
    "                'Accuracy: %{customdata:.4f}<extra></extra>'\n",
    "            ),\n",
    "            name='Data Points'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Contour Plot\",\n",
    "        xaxis_title=\"Hidden Size\",\n",
    "        yaxis_title=\"Number of Layers\",\n",
    "        xaxis=dict(showgrid=False),  # Remove x-axis grid lines\n",
    "        yaxis=dict(showgrid=False),\n",
    "        plot_bgcolor='white',        # Set background color to white\n",
    "        paper_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = analysis.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = analysis.results_df\n",
    "plot_contour(random, \"config/hidden_size\", \"config/num_layers\", \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the search space is sort of randomly sampled.\n",
    "Even though big parts are unexplored, it still looks like we find some hotspots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = analysis.get_best_config()\n",
    "best[\"accuracy\"] = analysis.best_result[\"accuracy\"]\n",
    "best_config[\"random\"] = best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we searched the hyperparameter space. Problem is, these spaces potentially can get\n",
    "pretty big. Let's imagine you have 10 hyperparameters, and every hyperparameter has 5\n",
    "possible (relevant) values, you already have $5^{10}$ possible combinations, which is almost 10 million. Even if checking of every configuration would take just 1 second, it would take more than a 100 days to check them all...This\n",
    "space can grow out of control pretty fast.\n",
    "\n",
    "Lets look at the best results we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"config/hidden_size\", \"config/num_layers\", \"accuracy\"]\n",
    "visualize.parallel_plot(analysis, columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the mean scores are sort of randomly distributed. This is a direct\n",
    "effect of random guessing parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this more rigorous with a gridsearch.\n",
    "The upside of this technique is that you will test every configuration.\n",
    "\n",
    "A huge downside is the inefficiency. Also, you will run experiments with combinations that might be not very promising, but very slow, which is pretty inefficient.\n",
    "\n",
    "\n",
    "One way to handle this is to use doubling as a strategy to scan the range: 16, 32, ..., 512. This is a bit more efficient.\n",
    "\n",
    "Typically, this can be a good idea for a first scan, to get a rough idea of the space.\n",
    "After you have done this, you can narrow your searchspace, and do a more fine grained search zoomed in on areas that seem promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"dropout\": 0.1,\n",
    "    \"epochs\": MAX_EPOCHS,\n",
    "    \"hidden_size\": tune.grid_search([16, 32, 64, 128, 256, 512]),\n",
    "    \"num_layers\": tune.grid_search([2, 4, 8]),\n",
    "    \"tune_dir\": tune_dir,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tic = time.time()\n",
    "\n",
    "analysis = tune.run(\n",
    "    tune_model,\n",
    "    config=config,\n",
    "    metric=\"valid_loss\",\n",
    "    mode=\"min\",\n",
    "    local_dir=str(tune_dir),\n",
    "    stop={\"training_iteration\": MAX_EPOCHS},\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "timer[\"ray_grid\"] = time.time() - tic\n",
    "\n",
    "best = analysis.get_best_config()\n",
    "best[\"accuracy\"] = analysis.best_result[\"accuracy\"]\n",
    "best_config[\"grid\"] = best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_results = pd.concat([all_results, analysis.results_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = analysis.results_df\n",
    "plot_contour(grid, \"config/hidden_size\", \"config/num_layers\", \"accuracy\", start=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we get a systematic scan, but large parts of the space are still unexplored, and we also explored parts that are really not very promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.parallel_plot(analysis, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.plot_timers(timer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we improve the search algorithm with a bayesian optimization.\n",
    "\n",
    "Note that the bayesian search algorithm will only work with continuous parameters. This is a problem for the number of layers, which is a discrete parameter. I fixed this by simply casting the parameters to an integer inside the model, which is not very elegant but it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.search.bayesopt import BayesOptSearch\n",
    "\n",
    "bayesopt = BayesOptSearch(random_search_steps=5)\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"dropout\": 0.1,\n",
    "    \"epochs\": MAX_EPOCHS,\n",
    "    \"hidden_size\": tune.uniform(16, 512),\n",
    "    \"num_layers\": tune.uniform(1, 8),\n",
    "    \"tune_dir\": tune_dir,\n",
    "}\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "analysis = tune.run(\n",
    "    tune_model,\n",
    "    config=config,\n",
    "    metric=\"valid_loss\",\n",
    "    mode=\"min\",\n",
    "    local_dir=str(tune_dir),\n",
    "    num_samples=N_EXPERIMENTS,\n",
    "    stop={\"training_iteration\": MAX_EPOCHS},\n",
    "    search_alg=bayesopt,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "timer[\"ray_bayes\"] = time.time() - tic\n",
    "\n",
    "best = analysis.get_best_config()\n",
    "best[\"accuracy\"] = analysis.best_result[\"accuracy\"]\n",
    "best_config[\"bayes\"] = best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat([all_results, analysis.results_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes = analysis.results_df\n",
    "plot_contour(bayes, \"config/hidden_size\", \"config/num_layers\", \"accuracy\", start=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, bayes really focuses on the promising areas. It is much more efficient than random search, and also more efficient than grid search.\n",
    "We have set the `random_search_steps` to 5, this means that we will do 5 random searches first, to get a good initial idea of the space. As you can see, 5 is a bit low, because it might lead to premature converging to a local optimum. You can increase this number to get a better initial idea of the space, but you will also need to increase the number of iterations after the initial random scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.parallel_plot(analysis, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.plot_timers(timer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_dict(best_config, orient=\"index\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperband\n",
    "\n",
    "Hyperband aborts runs early. Configs that are unpromising are abandoned before they complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "\n",
    "scheduler = AsyncHyperBandScheduler(\n",
    "    time_attr=\"training_iteration\", grace_period=1, reduction_factor=3, max_t=MAX_EPOCHS\n",
    ")\n",
    "\n",
    "config = {\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"dropout\": 0.1,\n",
    "    \"epochs\": MAX_EPOCHS,\n",
    "    \"hidden_size\": tune.randint(16, 512),\n",
    "    \"num_layers\": tune.randint(1, 8),\n",
    "    \"tune_dir\": tune_dir,\n",
    "}\n",
    "\n",
    "tic = time.time()\n",
    "analysis = tune.run(\n",
    "    tune_model,\n",
    "    config=config,\n",
    "    metric=\"valid_loss\",\n",
    "    mode=\"min\",\n",
    "    local_dir=str(tune_dir),\n",
    "    num_samples=N_EXPERIMENTS,\n",
    "    stop={\"training_iteration\": MAX_EPOCHS},\n",
    "    scheduler=scheduler,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "timer[\"ray_hyperband\"] = time.time() - tic\n",
    "\n",
    "best = analysis.get_best_config()\n",
    "best[\"accuracy\"] = analysis.best_result[\"accuracy\"]\n",
    "best_config[\"hyperband\"] = best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you study the iter column, you will see that some runs have been stopped early. This is exactly the point of hyperband: it tries to allocate resources to the most promising configurations.\n",
    "\n",
    "The downside of this, is that if you try to get a good view of the space, you get distorted results because comparing a model that has trained just 1 or 3 epochs with a model that has trained 100 epochs is not very fair..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat([all_results, analysis.results_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperband = analysis.results_df\n",
    "plot_contour(hyperband, \"config/hidden_size\", \"config/num_layers\", \"accuracy\", start=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.parallel_plot(analysis, columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But note that it is faster! This means you could do more runs in the same time, which might be a good tradeoff!\n",
    "Typically you will get better results if you scan the searchspace better by doing more runs, aborting the ones that are not promising and going on with the ones that seem to yield good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.plot_timers(timer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(best_config, orient=\"index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperbayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to combine Hyperband with Bayesian optimization, implemented as `TuneBOHB` in ray.\n",
    "However, `TuneBOHB` in ray is dependent on `hpbandster`, which is not mainained anymore.\n",
    "Unfortunately, a dependency of `hpbandster` is `netifaces`, which is also not maintained anymore.\n",
    "While `netifaces` does work on some hardware, it fails to build on some other hardware, which is a problem.\n",
    "\n",
    "To still use BOHB type algoritms, I am planning to implement either SMAC3 or BEHB in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "search = HyperOptSearch()\n",
    "\n",
    "scheduler = AsyncHyperBandScheduler(\n",
    "    time_attr=\"training_iteration\", grace_period=1, reduction_factor=3, max_t=MAX_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"input_size\": 3,\n",
    "    \"output_size\": 20,\n",
    "    \"dropout\": 0.1,\n",
    "    \"epochs\": MAX_EPOCHS,\n",
    "    \"hidden_size\": tune.randint(16, 512),\n",
    "    \"num_layers\": tune.randint(1, 8),\n",
    "    \"tune_dir\": tune_dir,\n",
    "}\n",
    "\n",
    "tic = time.time()\n",
    "analysis = tune.run(\n",
    "    tune_model,\n",
    "    config=config,\n",
    "    metric=\"valid_loss\",\n",
    "    mode=\"min\",\n",
    "    local_dir=str(tune_dir),\n",
    "    num_samples=N_EXPERIMENTS,\n",
    "    stop={\"training_iteration\": MAX_EPOCHS},\n",
    "    search_alg=search,\n",
    "    scheduler=scheduler,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "timer[\"ray_hyperopt\"] = time.time() - tic\n",
    "\n",
    "best = analysis.get_best_config()\n",
    "best[\"accuracy\"] = analysis.best_result[\"accuracy\"]\n",
    "best_config[\"hyperopt\"] = best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat([all_results, analysis.results_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperbayes = analysis.results_df\n",
    "plot_contour(hyperbayes, \"config/hidden_size\", \"config/num_layers\", \"accuracy\", start=0.3, size=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model combines bayesian optimization with hyperband. This is a good idea, because it combines the efficiency of bayesian optimization with the speed of hyperband."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.parallel_plot(analysis, columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.plot_timers(timer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(best_config, orient=\"index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour = all_results[all_results[\"training_iteration\"] == MAX_EPOCHS]\n",
    "plot_contour(contour, \"config/hidden_size\", \"config/num_layers\", \"accuracy\", start=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = time.time() - start\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DELETE:\n",
    "    import shutil\n",
    "    shutil.rmtree(tune_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "826f7c35c7cb2374ed015b71f995b28d51afc038e74920eb490e51986fe41e8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
